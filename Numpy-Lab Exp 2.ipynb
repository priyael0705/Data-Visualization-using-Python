{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0ab55b7",
   "metadata": {},
   "source": [
    "# Ex No 2.a Analyzing Academic Performance\n",
    "Problem Statement:\n",
    "Assess the performance trends of students across different subjects, focusing on data imperfections such as missing values, duplicates, and the need to uniquely identify records.\n",
    "\n",
    "Objective Scenario:\n",
    "A high school intends to analyze semester results to enhance teaching strategies and provide targeted support. The dataset includes student roll numbers but contains issues like missing entries and duplicates that must be addressed for accurate analysis.\n",
    "\n",
    "Dataset:\n",
    "Data is provided as a Python list containing tuples for each student's roll number followed by their scores in Mathematics, Science, and English. The list includes missing entries (represented as None) and intentionally duplicated records. Example: [(101, 45, 78, None), (102, 65, 56, 77), (103, 95, 85, 92), (102, 65, 56, 77), (104, 45, None, 88), (101, 45, 78, None)].\n",
    "\n",
    "Tasks to be performed:\n",
    "\n",
    "Data Conversion and Inspection:\n",
    "\n",
    "Convert the list of student records into a Numpy array.\n",
    "Identify and count the number of missing values in each subject.\n",
    "Detect duplicate entries based on student roll numbers.\n",
    "\n",
    "Data Cleaning:\n",
    "Handle missing values by replacing them with the median score of the respective subject.\n",
    "Remove duplicate records, ensuring data integrity by retaining only the first occurrence of each student's record.\n",
    "\n",
    "Data Normalization:\n",
    "Apply min-max normalization to the scores (excluding roll numbers) to scale them between 0 and 1. This adjustment facilitates fair comparisons across different subjects.\n",
    "\n",
    "Statistical Analysis:\n",
    "Calculate the normalized mean, median, and standard deviation of scores for each subject.\n",
    "Identify the subject with the highest variability in scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b61ec43",
   "metadata": {},
   "source": [
    "1. Data Conversion and Inspection\n",
    "This code converts the list of records into a pandas DataFrame, then identifies and counts missing values and duplicate records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b883e00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values count:\n",
      "Roll_No        0\n",
      "Mathematics    0\n",
      "Science        1\n",
      "English        2\n",
      "dtype: int64\n",
      "\n",
      "Duplicate entries:\n",
      "   Roll_No  Mathematics  Science  English\n",
      "0      101           45     78.0      NaN\n",
      "1      102           65     56.0     77.0\n",
      "3      102           65     56.0     77.0\n",
      "5      101           45     78.0      NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = [\n",
    "    (101, 45, 78, None),\n",
    "    (102, 65, 56, 77),\n",
    "    (103, 95, 85, 92),\n",
    "    (102, 65, 56, 77),\n",
    "    (104, 45, None, 88),\n",
    "    (101, 45, 78, None)\n",
    "]\n",
    "df = pd.DataFrame(data, columns=['Roll_No', 'Mathematics', 'Science', 'English'])\n",
    "missing_values_count = df.isnull().sum()\n",
    "print(\"Missing values count:\")\n",
    "print(missing_values_count)\n",
    "\n",
    "duplicate_entries = df[df.duplicated(subset=['Roll_No'], keep=False)]\n",
    "print(\"\\nDuplicate entries:\")\n",
    "print(duplicate_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebd1a73",
   "metadata": {},
   "source": [
    "2. Data Cleaning\n",
    "This section of the code handles missing values by replacing them with the median score and removes duplicate records based on the roll number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bf967f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned DataFrame after removing duplicates and imputing missing values:\n",
      "   Roll_No  Mathematics  Science  English\n",
      "0      101           45     78.0     82.5\n",
      "1      102           65     56.0     77.0\n",
      "2      103           95     85.0     92.0\n",
      "4      104           45     78.0     88.0\n"
     ]
    }
   ],
   "source": [
    "median_scores = df[['Mathematics', 'Science', 'English']].median(skipna=True)\n",
    "df_cleaned = df.copy()\n",
    "for col in ['Mathematics', 'Science', 'English']:\n",
    "    df_cleaned[col] = df_cleaned[col].fillna(median_scores[col])\n",
    "\n",
    "df_cleaned_unique = df_cleaned.drop_duplicates(subset=['Roll_No'], keep='first')\n",
    "print(\"Cleaned DataFrame after removing duplicates and imputing missing values:\")\n",
    "print(df_cleaned_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3a48aa",
   "metadata": {},
   "source": [
    "3. Data Normalization\n",
    "This code applies min-max normalization to the subject scores to scale them between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9459171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized DataFrame:\n",
      "   Roll_No  Mathematics   Science   English\n",
      "0      101          0.0  0.758621  0.366667\n",
      "1      102          0.4  0.000000  0.000000\n",
      "2      103          1.0  1.000000  1.000000\n",
      "4      104          0.0  0.758621  0.733333\n"
     ]
    }
   ],
   "source": [
    "score_cols = ['Mathematics', 'Science', 'English']\n",
    "df_normalized = df_cleaned_unique.copy()\n",
    "for col in score_cols:\n",
    "    min_val = df_normalized[col].min()\n",
    "    max_val = df_normalized[col].max()\n",
    "    df_normalized[col] = (df_normalized[col] - min_val) / (max_val - min_val)\n",
    "\n",
    "print(\"Normalized DataFrame:\")\n",
    "print(df_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dc8a8a",
   "metadata": {},
   "source": [
    "4. Statistical Analysis\n",
    "Finally, this code calculates the normalized mean, median, and standard deviation for each subject and identifies the subject with the highest variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55fd6af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical analysis on normalized scores:\n",
      "        Mathematics   Science   English\n",
      "mean       0.350000  0.629310  0.525000\n",
      "median     0.200000  0.758621  0.550000\n",
      "std        0.472582  0.434697  0.435784\n",
      "\n",
      "Subject with the highest variability: Mathematics\n"
     ]
    }
   ],
   "source": [
    "normalized_stats = df_normalized[score_cols].agg(['mean', 'median', 'std'])\n",
    "print(\"Statistical analysis on normalized scores:\")\n",
    "print(normalized_stats)\n",
    "\n",
    "highest_variability_subject = normalized_stats.loc['std'].idxmax()\n",
    "print(f\"\\nSubject with the highest variability: {highest_variability_subject}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e96f76",
   "metadata": {},
   "source": [
    "# Ex No 2.b Analyzing Healthcare Service Efficiency\n",
    "Problem Statement:\n",
    "Evaluate the performance trends of different hospital departments, addressing issues such as missing data, duplicates, and the need for unique identifiers.\n",
    "\n",
    "Objective Scenario:\n",
    "A hospital's administration wants to analyze patient treatment outcomes to enhance service delivery and provide targeted improvements in care. The dataset includes department ID numbers but contains issues like missing entries and duplicates that need accurate resolution for effective analysis.\n",
    "\n",
    "Dataset:\n",
    "Data is provided as a Python list containing tuples for each department's ID followed by their performance scores in patient satisfaction, treatment success rate, and wait times. The list includes missing entries (represented as None) and intentionally duplicated records. Example: [(701, 90, 95, None), (702, 88, 90, 85), (703, 92, None, 80), (702, 88, 90, 85), (704, 85, None, 78), (701, 90, 95, None)].\n",
    "\n",
    "Tasks to be performed:\n",
    "\n",
    "Data Conversion and Inspection:\n",
    "\n",
    "Convert the list of department records into a Numpy array.\n",
    "Identify and count the number of missing values in each performance metric.\n",
    "Detect duplicate entries based on department ID numbers.\n",
    "\n",
    "Data Cleaning:\n",
    "\n",
    "Handle missing values by replacing them with the median score of the respective metric.\n",
    "Remove duplicate records, ensuring data integrity by retaining only the first occurrence of each department's record.\n",
    "\n",
    "Data Normalization:\n",
    "\n",
    "Apply min-max normalization to the scores (excluding ID numbers) to scale them between 0 and 1. This adjustment facilitates fair comparisons across different metrics.\n",
    "\n",
    "Statistical Analysis:\n",
    "\n",
    "Calculate the normalized mean, median, and standard deviation of scores for each performance metric.\n",
    "Identify the metric with the highest variability in scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ed5653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = [\n",
    "    (701, 90, 95, None),\n",
    "    (702, 88, 90, 85),\n",
    "    (703, 92, None, 80),\n",
    "    (702, 88, 90, 85),\n",
    "    (704, 85, None, 78),\n",
    "    (701, 90, 95, None)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb32ad06",
   "metadata": {},
   "source": [
    "Convert the list to a DataFrame with appropriate column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f837ce94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=['Department_ID', 'Satisfaction', 'Success_Rate', 'Wait_Times'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e702276a",
   "metadata": {},
   "source": [
    "1. Data Conversion and Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d066d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initial DataFrame Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Department_ID  6 non-null      int64  \n",
      " 1   Satisfaction   6 non-null      int64  \n",
      " 2   Success_Rate   4 non-null      float64\n",
      " 3   Wait_Times     4 non-null      float64\n",
      "dtypes: float64(2), int64(2)\n",
      "memory usage: 324.0 bytes\n",
      "\n",
      "--- Missing Values Count ---\n",
      "Department_ID    0\n",
      "Satisfaction     0\n",
      "Success_Rate     2\n",
      "Wait_Times       2\n",
      "dtype: int64\n",
      "\n",
      "--- Duplicate Entries Based on Department_ID ---\n",
      "   Department_ID  Satisfaction  Success_Rate  Wait_Times\n",
      "0            701            90          95.0         NaN\n",
      "1            702            88          90.0        85.0\n",
      "3            702            88          90.0        85.0\n",
      "5            701            90          95.0         NaN\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Initial DataFrame Info ---\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n--- Missing Values Count ---\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\n--- Duplicate Entries Based on Department_ID ---\")\n",
    "duplicates = df[df.duplicated(subset=['Department_ID'], keep=False)]\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403a5c88",
   "metadata": {},
   "source": [
    " Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d3bd2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cleaned DataFrame after Imputing and Removing Duplicates ---\n",
      "   Department_ID  Satisfaction  Success_Rate  Wait_Times\n",
      "0            701            90          95.0        82.5\n",
      "1            702            88          90.0        85.0\n",
      "2            703            92          92.5        80.0\n",
      "4            704            85          92.5        78.0\n"
     ]
    }
   ],
   "source": [
    "median_scores = df[['Satisfaction', 'Success_Rate', 'Wait_Times']].median(skipna=True)\n",
    "df_cleaned = df.copy()\n",
    "for col in ['Satisfaction', 'Success_Rate', 'Wait_Times']:\n",
    "    df_cleaned[col] = df_cleaned[col].fillna(median_scores[col])\n",
    "df_cleaned_unique = df_cleaned.drop_duplicates(subset=['Department_ID'], keep='first')\n",
    "\n",
    "print(\"\\n--- Cleaned DataFrame after Imputing and Removing Duplicates ---\")\n",
    "print(df_cleaned_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a42d509",
   "metadata": {},
   "source": [
    "3. Data Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61989ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Normalized DataFrame ---\n",
      "   Department_ID  Satisfaction  Success_Rate  Wait_Times\n",
      "0            701      0.714286           1.0    0.642857\n",
      "1            702      0.428571           0.0    1.000000\n",
      "2            703      1.000000           0.5    0.285714\n",
      "4            704      0.000000           0.5    0.000000\n"
     ]
    }
   ],
   "source": [
    "score_cols = ['Satisfaction', 'Success_Rate', 'Wait_Times']\n",
    "df_normalized = df_cleaned_unique.copy()\n",
    "for col in score_cols:\n",
    "    min_val = df_normalized[col].min()\n",
    "    max_val = df_normalized[col].max()\n",
    "    df_normalized[col] = (df_normalized[col] - min_val) / (max_val - min_val)\n",
    "\n",
    "print(\"\\n--- Normalized DataFrame ---\")\n",
    "print(df_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d563f774",
   "metadata": {},
   "source": [
    "4. Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12e53009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Statistical Analysis on Normalized Scores ---\n",
      "        Satisfaction  Success_Rate  Wait_Times\n",
      "mean        0.535714      0.500000    0.482143\n",
      "median      0.571429      0.500000    0.464286\n",
      "std         0.426583      0.408248    0.433993\n",
      "\n",
      "--- Metric with Highest Variability ---\n",
      "The metric with the highest variability is: Wait_Times (Standard Deviation: 0.4340)\n"
     ]
    }
   ],
   "source": [
    "normalized_stats = df_normalized[score_cols].agg(['mean', 'median', 'std'])\n",
    "print(\"\\n--- Statistical Analysis on Normalized Scores ---\")\n",
    "print(normalized_stats)\n",
    "highest_variability_metric = normalized_stats.loc['std'].idxmax()\n",
    "highest_variability_std = normalized_stats.loc['std'].max()\n",
    "\n",
    "print(f\"\\n--- Metric with Highest Variability ---\")\n",
    "print(f\"The metric with the highest variability is: {highest_variability_metric} (Standard Deviation: {highest_variability_std:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ae6915",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
